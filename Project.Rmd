---
title: "Data Analytics CA Pair Project - VR Jungian Sandplay"
author: "Charlie Duff, Adam Heaton, Ademide Adenuga"
date: "December, 2022"
output:
  pdf_document:
    toc: yes
  html_document:
    code_folding: show
    toc: yes
    toc_float: no
    number_sections: yes
    df_print: paged
  word_document:
    toc: yes
    
---
```{r Load Data, echo=FALSE}
file_name = "data/daie_ca3_data_8.csv"
patient_data <- read.csv(file_name)

patient_data$pre_trial_cpss[is.na(patient_data$pre_trial_cpss)] <- mean(patient_data$pre_trial_cpss,na.rm = TRUE)


```


# Abstract

## Aim and Rationale
The aim and rationale of this project is to formulate a single hypothesis based on a set of data we were given on an experiment conducted to attempt to determine the effectiveness of use of VR technology in Jungian Sandbox therapy, comparing the effectiveness of the approaches based on the data we were provided, and cleaning up any data that requires cleanup.

## Participants and setting
Participants in the study are psychotherapy patients undergoing treatment for PTSD with Jungian Sandplay alongside a therapist, using either traditional Cognitive Behavioural Therapy or in a virtual reality environment.

## Experiment design
Each participant spent 50 minutes per week for 12 weeks with a therapist, under three testing groups:

**Control:**
Undergoing traditional CBT with a therapist.

**Static:**
Using the VR app with non-animated model content.

**Animated:**
Using the VR app with animated content. 


## Results gathering
Participants and their therapists were asked to rate their level of PTSD between 0-10 before and after their treatment, with 0 being no PTSD and 10 being the highest level of PTSD.

## Major findings
We found that the average PTSD rating for each testing group decreased after treatment. Post-trial results were more widely dispersed than pre-trial results, leading us to conclude that the treatment was not as effective for some participants as others. Self-reported results are more correlated than observer-reported results, leading us to conclude that the treatment seemed more beneficial for participants than observers.

## Findings/Implications
An outlier was discovered in the female control section of our data. This outlier's data could have affected our mean calculations for each set of data. Both post trials reports failed tests for normality showing a possibility of outliers being present in our data or clusters of specific values being found in our data.

# Introduction

## Topic and context
Jungian Sandplay is a psychotherapeutic method where participants play with sand and miniature objects to create an image that can reflect internal experiences and difficulties.
Post-Traumatic Stress Disorder (PTSD) is a psychological condition caused by witnessing or experiencing an event or situation.
Jungian Sandplay has been shown to decrease levels of PTSD in individuals.

## Rationale
The Rationale behind this experiment was to determine if using Virtual Reality (VR) technology in a Jungian Sandbox setting could be beneficial in reducing the PTSD levels in patients.

## Hypothesis
Our null hypothesis for this experiment is that post-trial values for OR results should correlate with post-trial CPSS results. This would infer that therapists observe as much of a benefit from the trial as the participant.

Our alternate hypothesis is that OR values will not correlate with the CPSS values.

Following tests done to check normality done to our data, we found that the post CPSS and OR values of the data were not normally distributed. This casts doubt on the quality of data collected for the post CPSS and OR values as outliers or skewed clusters could be present in our data causing us to reject our null hypothesis. Our dot plot shows a more positive correlation between pre and post-trial CPSS than pre and post-trial OR.


# Method

## Participants
Participants of this experiment were psychotherapy patients undergoing treatment for PTSD, aged between 18 - 25 years old with no exact ages of the participants recorded. 150 participants were recorded in this study with an equal amount of male and female participants recorded (Male = 75 / Female = 75).

Participants were broken into 3 groups using random sampling. These groups were then assigned one of three testing groups (Control, Static, Animated).

## Design
Each participant had their level of PTSD rated between 0-10 both before and after their 12 weeks of treatment, assessed by themselves (Child PTSD Symptom Scale Seld Report - SR) and by their therapist (observer reported – OR). These results were collated in a CSV file tracking the participants’ gender, test group, pre and post-trial self-reported results, and pre and post-trial observer reported results.

## Materials
The materials used for this experiment were the results of the pre and post-trials, both independently observed, and the results stemming from records by the therapists. Additionally, RStudio was used to collate all the data and information needed to be documented.

## Procedure
Patients within this experiment underwent 12 weeks of Jungian sand play treatment. Results of this treatment were recorded at the start and end of this experiment. Results we compiled into four sections. The CPSS (Self report) and OR (Observed report) were recorded both pre and post this experiment.

We imported the dataset into R studio and began running a series of tests to determine the validity of the data and to generate a hypothesis based on the data set we had been provided. Using imputation, we were able to resolve the missing data in our “pre_trial_ccpp” section by using the mean of that column to get a value to insert into that missing data. We calculated the mean, median, and standard deviation of the datasets along with graphing our datasets to better understand our data to help us formulate a hypothesis. We used the Shapiro wilk test to determine the normality of our dataset. We also calculated the 95% confidence interval for each of our datasets to help generate a more accurate representation of our true mean.

# Results
```{r table, echo=FALSE}
knitr::kable(patient_data,
  align = c('c'), # a vector with 'c', 'l', or 'r' values
  digits = 2,
  caption = "Patient Data")

pre_trial_cpss_mean <- mean(patient_data$pre_trial_cpss)

```

 
```{r Summary, echo=FALSE}
summary(patient_data)

```
## Graphs
```{r Graphs, echo=FALSE}

#Density Plots
plot(density(patient_data$pre_trial_cpss,na.rm = TRUE), main = "Pre-Trial CPSS results", xlim =c(0,10), ylim=c(0,0.5))
plot(density(patient_data$post_trial_cpss,na.rm = TRUE), main = "Post-Trial CPSS results", xlim =c(0,10), ylim=c(0,0.5))

plot(density(patient_data$pre_trial_or,na.rm = TRUE), main = "Pre-Trial OR results", xlim =c(0,10), ylim=c(0,0.5))
plot(density(patient_data$post_trial_or,na.rm = TRUE), main = "Post-Trial OR results", xlim =c(0,10), ylim=c(0,0.5))

plot(density(patient_data$pre_trial_cpss,na.rm = TRUE), main = "Density plot of each dataset", sub = "RED = Pre-CPSS, GRN = Pre-OR, PUR = Post-CPSS, BLU = Post-OR", xlim =c(0,10), ylim=c(0,0.5), col="red")
lines(density(patient_data$post_trial_cpss,na.rm = TRUE), col = "purple" )
lines(density(patient_data$pre_trial_or,na.rm = TRUE), col = "green")
lines(density(patient_data$post_trial_or,na.rm = TRUE), col = "blue")
```
In this graph 'Bandwidth' only applies to the red line.

```{r Graphs2, echo=FALSE}
#Histogram
hist(patient_data$pre_trial_cpss, xlim=c(0,10), ylim =c(0,60), breaks = 20, main = "Histogram - Pre Trial CPSS", xlab = "CPSS Values")
hist(patient_data$post_trial_cpss, xlim=c(0,10), ylim =c(0,60), breaks = 20, main = "Histogram - Post Trial CPSS", xlab = "CPSS Values")
hist(patient_data$pre_trial_or, xlim=c(0,10), ylim =c(0,60), breaks = 20, main = "Histogram - Pre Trial OR", xlab = "OR Values")
hist(patient_data$post_trial_or, xlim=c(0,10), ylim =c(0,60), breaks = 20, main = "Histogram - Post Trial OR", xlab = "OR Values")


#CPSS Control, Static, Animated

plot(patient_data$pre_trial_cpss[51:100] ~ patient_data$post_trial_cpss[51:100], type="p",xlim = c(0,10), ylim = c(0,10), patient_data, main = "Self Reported Data - Control CPSS", xlab = "Pre-Trial Report", ylab = "Post Trial Report")

plot(patient_data$pre_trial_cpss[1:50] ~ patient_data$post_trial_cpss[1:50], type="p",xlim = c(0,10), ylim = c(0,10), patient_data, main = "Self Reported Data - Static CPSS", xlab = "Pre-Trial Report", ylab = "Post Trial Report")

plot(patient_data$pre_trial_cpss[101:150] ~ patient_data$post_trial_cpss[101:150], type="p",xlim = c(0,10), ylim = c(0,10), patient_data, main = "Self Reported Data - Animated CPSS", xlab = "Pre-Trial Report", ylab = "Post Trial Report")

#OR Control, Static, Animated

plot(patient_data$pre_trial_or[51:100] ~ patient_data$post_trial_or[51:100], type="p",xlim = c(0,10), ylim = c(0,10), patient_data, main = "Observer Reported Data - Control", xlab = "Pre-Trial Report", ylab = "Post Trial Report")

plot(patient_data$pre_trial_or[1:50] ~ patient_data$post_trial_or[1:50], type="p",xlim = c(0,10), ylim = c(0,10), patient_data, main = "Observer Reported Data - Static", xlab = "Pre-Trial Report", ylab = "Post Trial Report")

plot(patient_data$pre_trial_or[101:150] ~ patient_data$post_trial_or[101:150], type="p",xlim = c(0,10), ylim = c(0,10), patient_data, main = "Observer Reported Data - Animated", xlab = "Pre-Trial Report", ylab = "Post Trial Report")

```

## Descriptive statistics
```{r DesStats, include=FALSE}
# Getting Static , Control, and Animed Mean(s) for CPSS Dataset
pre_trial_cpss_meanStatic <- mean(patient_data$pre_trial_cpss[1:50],na.rm = TRUE )
post_trial_cpss_meanStatic <- mean(patient_data$post_trial_cpss[1:50],na.rm = TRUE )

pre_trial_cpss_meanControl <- mean(patient_data$pre_trial_cpss[51:100],na.rm = TRUE )
post_trial_cpss_meanControl <- mean(patient_data$post_trial_cpss[51:100],na.rm = TRUE )

pre_trial_cpss_meanAnimated <- mean(patient_data$pre_trial_cpss[101:150],na.rm = TRUE )
post_trial_cpss_meanAnimated <- mean(patient_data$post_trial_cpss[101:150],na.rm = TRUE )


# Getting Static , Control, and Animed Mean(s) for OR Dataset
pre_trial_or_meanStatic <- mean(patient_data$pre_trial_or[1:50],na.rm = TRUE )
post_trial_or_meanStatic <- mean(patient_data$post_trial_or[1:50],na.rm = TRUE )

pre_trial_or_meanControl <- mean(patient_data$pre_trial_or[51:100],na.rm = TRUE )
post_trial_or_meanControl <- mean(patient_data$post_trial_or[51:100],na.rm = TRUE )

pre_trial_or_meanAnimated <- mean(patient_data$pre_trial_or[101:150],na.rm = TRUE )
post_trial_or_meanAnimated <- mean(patient_data$post_trial_or[101:150],na.rm = TRUE )

## Getting Static , Control, and Animated Standard Deviations for CPSS Dataset
pre_trial_cpss_stdStatic <- sd(patient_data$pre_trial_cpss[1:50],na.rm = TRUE )
post_trial_cpss_stdStatic <- sd(patient_data$post_trial_cpss[1:50],na.rm = TRUE )

pre_trial_cpss_stdControl <- sd(patient_data$pre_trial_cpss[51:100],na.rm = TRUE )
post_trial_cpss_stdControl <- sd(patient_data$post_trial_cpss[51:100],na.rm = TRUE )

pre_trial_cpss_stdAnimated <- sd(patient_data$pre_trial_cpss[101:150],na.rm = TRUE )
post_trial_cpss_stdAnimated <- sd(patient_data$post_trial_cpss[101:150],na.rm = TRUE )


## Getting Static , Control, and Animated Standard Deviations for OR Dataset
pre_trial_or_stdStatic <- sd(patient_data$pre_trial_or[1:50],na.rm = TRUE )
post_trial_or_stdStatic <- sd(patient_data$post_trial_or[1:50],na.rm = TRUE )

pre_trial_or_stdControl <- sd(patient_data$pre_trial_or[51:100],na.rm = TRUE )
post_trial_or_stdControl <- sd(patient_data$post_trial_or[51:100],na.rm = TRUE )

pre_trial_or_stdAnimated <- sd(patient_data$pre_trial_or[101:150],na.rm = TRUE )
post_trial_or_stdAnimated <- sd(patient_data$post_trial_or[101:150],na.rm = TRUE )

# Getting Mean for CPSS and OR Dataset
pre_trial_cpss_mean <- mean(patient_data$pre_trial_cpss,na.rm = TRUE )
post_trial_cpss_mean <- mean(patient_data$post_trial_cpss)
pre_trial_or_mean<- mean(patient_data$pre_trial_or)
post_trial_or_mean <- mean(patient_data$post_trial_or)

# Getting Standard Deviation for CPSS and OR Dataset
pre_trial_cpss_std <- sd(patient_data$pre_trial_cpss,na.rm = TRUE )
post_trial_cpss_std <- sd(patient_data$post_trial_cpss)
pre_trial_or_std<- sd(patient_data$pre_trial_or)
post_trial_or_std <- sd(patient_data$post_trial_or)

```
After calculating the individual means for each of the groups of each data set (static pre_trial_or, control pre-trial_or) we determined that across all the data sets there is a consistent decrease in recorded PTSD levels of the patients post the experiment with a similar decrease in PTSD levels across each group (Control, Static, Animated).

**CPSS Means (Static Pre/Post , Control Pre/Post, Animated Pre/Post)**

Static Pre trial CPSS Mean = `r pre_trial_cpss_meanStatic`

Static Post trial CPSS Mean = `r post_trial_cpss_meanStatic`

Control Pre trial CPSS Mean = `r pre_trial_cpss_meanControl`

Control Post trial CPSS Mean = `r post_trial_cpss_meanControl`

Animated Pre trial CPSS Mean = `r pre_trial_cpss_meanAnimated`

Animated Post trial CPSS Mean = `r post_trial_cpss_meanAnimated`


**OR Means (Static Pre/Post , Control Pre/Post, Animated Pre/Post)**

Static Pre trial OR Mean = `r pre_trial_or_meanStatic`

Static Post trial OR Mean = `r post_trial_or_meanStatic`

Control Pre trial OR Mean = `r pre_trial_or_meanControl`

Control Post trial OR Mean = `r post_trial_or_meanControl`

Animated Pre trial OR Mean = `r pre_trial_or_meanAnimated`

Animated Post trial OR Mean = `r post_trial_or_meanAnimated`


**CPSS Standard Deviation (Static Pre/Post , Control Pre/Post, Animated Pre/Post)**

Static Pre trial CPSS Standard Deviation = `r pre_trial_cpss_stdStatic`

Static Post trial CPSS Standard Deviation = `r post_trial_cpss_stdStatic`

Control Pre trial CPSS Standard Deviation = `r pre_trial_cpss_stdControl`

Control Post trial CPSS Standard Deviation = `r post_trial_cpss_stdControl`

Animated Pre trial CPSS Standard Deviation = `r pre_trial_cpss_stdAnimated`

Animated Post trial CPSS Standard Deviation = `r post_trial_cpss_stdAnimated`

**OR Standard Deviation (Static Pre/Post , Control Pre/Post, Animated Pre/Post)**

Static Pre trial OR Standard Deviation = `r pre_trial_or_stdStatic`

Static Post trial OR Standard Deviation = `r post_trial_or_stdStatic`

Control Pre trial OR Standard Deviation = `r pre_trial_or_stdControl`

Control Post trial OR Standard Deviation = `r post_trial_or_stdControl`

Animated Pre trial OR Standard Deviation = `r pre_trial_or_stdAnimated`

Animated Post trial OR Standard Deviation = `r post_trial_or_stdAnimated`

**CPSS Mean (Pre/Post-trial)**

Pre trial CPSS Mean = `r pre_trial_cpss_mean`

Post trial CPSS Mean = `r post_trial_cpss_mean`

**OR Mean (Pre/Post-trial)**

Pre trial OR Mean = `r pre_trial_or_mean`

Post trial OR Mean = `r post_trial_or_mean`

**CPSS Standard Deviation (Pre/Post-trial)**

Pre trial CPSS Standard Deviation = `r pre_trial_cpss_std`

Post trial CPSS Standard Deviation = `r post_trial_cpss_std`

**OR Standard Deviation  (Pre/Post-trial)**

Pre trial OR Standard Deviation = `r pre_trial_or_std`

Post trial OR Standard Deviation = `r post_trial_or_std`

## Inferential statistics
If the participants in this study are an accurate reflection of 18-25 year olds in treatment for PTSD, we can infer that traditional CBT therapy as well the Jungian Sandplay VR app can reduce self-reported levels of PTSD for people with similar attributes in a general population.

## Statistical tests
```{r Shapiro-Wilk, include=FALSE}

#perform shapiro-wilk test
result_sw_ptcpss <- shapiro.test(patient_data$pre_trial_cpss)
result_sw_ptcpss
result_sw_postcpss <- shapiro.test(patient_data$post_trial_cpss)
result_sw_postcpss
result_sw_ptor <- shapiro.test(patient_data$pre_trial_or)
result_sw_ptor
result_sw_postor <- shapiro.test(patient_data$post_trial_or)
result_sw_postor


```

A `r result_sw_ptcpss$method` was conducted on each of the data sets

**Pre-trial CPSS SW Result =** `r round(result_sw_ptcpss$p.value, 4)`

**Post-trial CPSS SW Result =** `r round(result_sw_postcpss$p.value, 4)`

**Pre-trial OR SW Result =** `r round(result_sw_ptor$p.value, 4)`

**Post-trial OR SW Result =** `r round(result_sw_postor$p.value, 4)`


From the output obtained we can assume normality for both pre-trial results as the p-values are greater than 0.05, while both post-trial results fail this normality test as they are less than 0.05. 

From the 'Density plot of each dataset' graph we can see a strong correlation between the post-trial results, whereas the pre-trial results are more varied between reports.


## Confidence Intervals
```{r Confidence Interval, include=FALSE}

#perform 95% Confidence Interval test
ci_error_precpss <- qt(0.975,df=length(patient_data$pre_trial_cpss)-1)*sd(patient_data$pre_trial_cpss)/sqrt(length(patient_data$pre_trial_cpss))
ci_error_precpss_left <- mean(patient_data$pre_trial_cpss)-ci_error_precpss
ci_error_precpss_right <- mean(patient_data$pre_trial_cpss)+ci_error_precpss

ci_error_postcpss <- qt(0.975,df=length(patient_data$post_trial_cpss)-1)*sd(patient_data$post_trial_cpss)/sqrt(length(patient_data$post_trial_cpss))
ci_error_postcpss_left <- mean(patient_data$post_trial_cpss)-ci_error_postcpss
ci_error_postcpss_right <- mean(patient_data$post_trial_cpss)+ci_error_postcpss

ci_error_preor <- qt(0.975,df=length(patient_data$pre_trial_or)-1)*sd(patient_data$pre_trial_or)/sqrt(length(patient_data$pre_trial_or))
ci_error_preor_left <- mean(patient_data$pre_trial_or)-ci_error_preor
ci_error_preor_right <- mean(patient_data$pre_trial_or)+ci_error_preor

ci_error_postor <- qt(0.975,df=length(patient_data$post_trial_or)-1)*sd(patient_data$post_trial_or)/sqrt(length(patient_data$post_trial_or))
ci_error_postor_left <- mean(patient_data$post_trial_or)-ci_error_postor
ci_error_postor_right <- mean(patient_data$post_trial_or)+ci_error_postor


```

**95% CI for pre-trial CPSS =** (`r ci_error_precpss_left` , `r ci_error_precpss_right`)

**95% CI for post-trial CPSS =** (`r ci_error_postcpss_left` , `r ci_error_postcpss_right`)

**95% CI for pre-trial OR  =** (`r ci_error_preor_left` , `r ci_error_preor_right`)

**95% CI for post-trial OR =** (`r ci_error_postor_left` , `r ci_error_postor_right`)



## Magnitude and direction of results

```{r Regression, echo=FALSE}

#Line of best fit for CPSS
plot(patient_data$pre_trial_cpss[1:150] ~ patient_data$post_trial_cpss[1:150], type="p",xlim = c(0,10), ylim = c(0,10), patient_data, main = "Self Reported Data", xlab = "Pre-Trial Report", ylab = "Post-Trial Report")
abline(lm(patient_data$pre_trial_cpss[1:150]~patient_data$post_trial_cpss[1:150]))

#Line of best fit for OR
plot(patient_data$pre_trial_or[1:150] ~ patient_data$post_trial_or[1:150], type="p",xlim = c(0,10), ylim = c(0,10), patient_data, main = "Observer Reported Data", xlab = "Pre-Trial Report", ylab = "Post-Trial Report")
abline(lm(patient_data$pre_trial_or[1:150]~patient_data$post_trial_or[1:150]))

#Entire Dataset
plot(patient_data$pre_trial_cpss[1:150] ~ patient_data$post_trial_cpss[1:150], type="p",xlim = c(0,10), ylim = c(0,10), patient_data, main = "Scatter Plot of entire dataset", xlab = "Pre-Trial Report", ylab = "Post Trial Report", col="red", sub = "Red = CPSS, Blue = OR", cex = .5)
points(patient_data$pre_trial_or[1:150] ~ patient_data$post_trial_or[1:150], col="blue", cex = .5)


```

By plotting the pre- and post-trial CPSS against one another and the pre- and post-trial OR against one another we can see the CPSS values have a more positive association with one another. The OR values lack this association and appear to be more dispersed and random than the CPSS values.

# Discussion

## Outline findings and relation to the hypothesis
Our null hypothesis for this experiment is that post-trial values for OR results should correlate with post-trial CPSS results. This would infer that therapists observe as much of a benefit from the trial as the participant.

Our alternate hypothesis is that OR values will not correlate with the CPSS values.

The results of our Shapiro-Wilkes test proved that the Pre-Trial results were normalised, while the post-trial results were not. Our dot plots also visually confirmed that the OR results did not align with the CPSS results. This goes against our null hypothesis that post-trial OR values should correlate with post-trial CPSS results.

Because of these results, we decided that our alternate hypothesis was correct.

## Limitations
The initial decision to impute the missing values instead of ignoring them could have led to a different set of results. However, the outcome of the experiment would likely stay the same.

# References
Help with getting mean of data while data is missing from column *[Stack Overflow](https://stackoverflow.com/questions/23163863/mean-of-a-column-in-a-data-frame-given-the-columns-name)

Removing Na's by Column *[GeeksforGeeks](https://www.geeksforgeeks.org/remove-rows-with-na-in-one-column-of-r-dataframe/)

How to Handle Missing Data in a Dataset *[freeCodeCamp](https://www.freecodecamp.org/news/how-to-handle-missing-data-in-a-dataset/)

How to Impute Missing Values in R? *[GeeksforGeeks](https://www.geeksforgeeks.org/how-to-impute-missing-values-in-r/)

First 10 entries in a bar plot
*[StackOverflow](https://stackoverflow.com/questions/37524701/how-do-i-barplot-only-the-first-10-entries-in-a-frequency-table-in-r)

Calculate confidence interval *[Cyclismo](https://www.cyclismo.org/tutorial/R/confidence.html)

How to Create a Scatterplot with a Regression Line in R? *[GeeksforGeeks](https://www.geeksforgeeks.org/how-to-create-a-scatterplot-with-a-regression-line-in-r/)
